{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8094684",
   "metadata": {},
   "source": [
    "# Bias Amplification by Quantitative Misrepresentation\n",
    "\n",
    "This notebook guides you through the process of bias amplification by quantitative misrepresentation. This demonstration uses MIDRC open A1 cheset X-ray image data as the example, and provides you with the instruction on how to process the data, train and deploy the model, as well as bias visualization.\n",
    "Quantitative misrepresentation (i.e., data set skew) is systematically applied to the training set to simulate different levels of selection bias. Specifically, the data used during development are selected such that the disease prevalence varies between patient subgroups. The degree to which bias is promoted can be controlled by changing the degree to which the prevalence varies between subgroups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aedbe2",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "To amplify the model bias by quantitative misrepresentation, the first step is to vary the disease prevalence within each subgroup in the **training set** while maintaining constant overall disease prevalence and subgroup distribution. \n",
    "This demonstration takes patient sex subgroup (male and female) as an example. You can run the following code to sample the disease prevalence to 10%, 25%, 50%, 75% and 90% in \"F\" (memale) subgroup, while the disease prevalence in \"M\" (male) will be 90%, 75%, 50%, 25% and 10% repectively. Noted that training set with 50% diease prevalence in each subgroup serves as the baseline.\n",
    "The code will save resulted training set *.csv* files and renamed with subgroup disease prevalence (e.g., training set with 10% disease prevalence in female subgroup will be saved as *train_10FP.csv*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e53231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start data split of 0.1 for F\n",
      "\n",
      "Start data split of 0.25 for F\n",
      "\n",
      "Start data split of 0.5 for F\n",
      "\n",
      "Start data split of 0.75 for F\n",
      "\n",
      "Start data split of 0.9 for F\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# manipulate subgroup disease prevalence in training/validation set\n",
    "main_dir = \"/gpfs_projects/yuhang.zhang/OUT/2022_CXR/test/RAND_0\"\n",
    "%run ../src/utils/quantitative_misrepresentation_data_process.py --input_file \"train.csv\" \\\n",
    "                                                                 --prevalences 0.1 0.25 0.5 0.75 0.9 \\\n",
    "                                                                 --test_subgroup \"F\" \\\n",
    "                                                                 --in_dir \"{main_dir}\" \\\n",
    "                                                                 --save_dir \"{main_dir}\"\n",
    "%run ../src/utils/quantitative_misrepresentation_data_process.py --input_file \"validation.csv\" \\\n",
    "                                                                 --prevalences 0.1 0.25 0.5 0.75 0.9 \\\n",
    "                                                                 --test_subgroup \"F\" \\\n",
    "                                                                 --in_dir \"{main_dir}\" \\\n",
    "                                                                 --save_dir \"{main_dir}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bbcce",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "After data preprocessing is done, you can run the following cell to train models with these different training sets. In this demonstration we uses *ResNet-18* as the example network architecture, and pre-trained weights trained from a contrastive\n",
    "self-supervised learning (CSL) approach and data from the CheXpert data. This weight file can be found under */example/* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04af6d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start experiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 15:14:40.637353: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-29 15:14:40.702802: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 15:15:18.180719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full fine tuning selected\n",
      "['patient_id', 'Path', 'M', 'F', 'White', 'Black', 'Yes', 'No']\n",
      "['patient_id', 'Path', 'M', 'F', 'White', 'Black', 'Yes', 'No']\n",
      "Training...\n",
      "EPOCH\tTR-AVG-LOSS\tVD-AUC\n",
      "> 0\t0.64736\t\t0.60740\n",
      "> 1\t0.47892\t\t0.58973\n",
      "> 2\t0.37559\t\t0.59448\n",
      "> 3\t0.29787\t\t0.58872\n",
      "> 4\t0.27418\t\t0.58733\n",
      "> 5\t0.25196\t\t0.58974\n",
      "> 6\t0.23189\t\t0.58815\n",
      "> 7\t0.22453\t\t0.58927\n",
      "> 8\t0.22361\t\t0.58897\n",
      "> 9\t0.21520\t\t0.58852\n",
      "> 10\t0.21679\t\t0.58867\n",
      "> 11\t0.21191\t\t0.58887\n",
      "> 12\t0.21539\t\t0.58925\n",
      "> 13\t0.21745\t\t0.58923\n",
      "> 14\t0.21056\t\t0.58958\n",
      "Final epoch model saved to: /gpfs_projects/yuhang.zhang/OUT/2022_CXR/test/RAND_0//10FP/pytorch_last_epoch_model.onnx\n",
      "Final epoch model saved to: /gpfs_projects/yuhang.zhang/OUT/2022_CXR/test/RAND_0//10FP/best_auc_model.onnx\n",
      "END.\n",
      "Start experiment...\n",
      "Full fine tuning selected\n",
      "['patient_id', 'Path', 'M', 'F', 'White', 'Black', 'Yes', 'No']\n",
      "['patient_id', 'Path', 'M', 'F', 'White', 'Black', 'Yes', 'No']\n",
      "Training...\n",
      "EPOCH\tTR-AVG-LOSS\tVD-AUC\n",
      "> 0\t0.68779\t\t0.61231\n",
      "> 1\t0.59941\t\t0.64265\n",
      "> 2\t0.52161\t\t0.63612\n",
      "> 3\t0.45530\t\t0.63837\n",
      "> 4\t0.42564\t\t0.63511\n",
      "> 5\t0.39907\t\t0.62741\n",
      "> 6\t0.37967\t\t0.62750\n",
      "> 7\t0.37197\t\t0.62690\n",
      "> 8\t0.36401\t\t0.62701\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "exp_list = [\"10FP\", \"25FP\", \"50FP\", \"75FP\", \"90FP\"]\n",
    "for EXP in exp_list:\n",
    "    %run ../src/utils/model_train.py -i \"{main_dir}/{EXP}_train.csv\" \\\n",
    "                                     -v \"{main_dir}/validation.csv\" \\\n",
    "                                     -o \"{main_dir}/{EXP}\" \\\n",
    "                                     -l \"{main_dir}/{EXP}/run_log.log\" \\\n",
    "                                     -c \"checkpoint_csl.pth.tar\" \\\n",
    "                                     -p \"adam\" \\\n",
    "                                     -g 0 \\\n",
    "                                     --pretrained_weights True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b91a71",
   "metadata": {},
   "source": [
    "## Model Inference\n",
    "\n",
    "After model training is done, you can deploy the models on the independent testing set by running the inference code below. The inference code will save prediction scores as *results__.tsv* files under the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c86c8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient_id', 'Path', 'M', 'F', 'White', 'Black', 'Yes', 'No']\n",
      "Inferencing now ...\n",
      " onnxruntime available providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      " onnxruntime running on: GPU\n",
      " There were 1048 ROIs in the lists\n",
      " AUROC = 0.584017\n",
      " Time taken:  175.85512603400275\n",
      "END.\n",
      "['patient_id', 'Path', 'M', 'F', 'White', 'Black', 'Yes', 'No']\n",
      "Inferencing now ...\n",
      " onnxruntime available providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      " onnxruntime running on: GPU\n",
      " There were 1048 ROIs in the lists\n",
      " AUROC = 0.639466\n",
      " Time taken:  74.80611474101897\n",
      "END.\n",
      "['patient_id', 'Path', 'M', 'F', 'White', 'Black', 'Yes', 'No']\n",
      "Inferencing now ...\n",
      " onnxruntime available providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      " onnxruntime running on: GPU\n",
      " There were 1048 ROIs in the lists\n",
      " AUROC = 0.682226\n",
      " Time taken:  76.51662474789191\n",
      "END.\n",
      "['patient_id', 'Path', 'M', 'F', 'White', 'Black', 'Yes', 'No']\n",
      "Inferencing now ...\n",
      " onnxruntime available providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      " onnxruntime running on: GPU\n",
      " There were 1048 ROIs in the lists\n",
      " AUROC = 0.670980\n",
      " Time taken:  75.40291022800375\n",
      "END.\n",
      "['patient_id', 'Path', 'M', 'F', 'White', 'Black', 'Yes', 'No']\n",
      "Inferencing now ...\n",
      " onnxruntime available providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      " onnxruntime running on: GPU\n",
      " There were 1048 ROIs in the lists\n",
      " AUROC = 0.595019\n",
      " Time taken:  75.11271558399312\n",
      "END.\n"
     ]
    }
   ],
   "source": [
    "# model inference\n",
    "for exp in exp_list:\n",
    "    %run ../src/utils/model_inference.py -i \"{main_dir}/independent_test.csv\" \\\n",
    "                                         -w \"{main_dir}/pytorch_last_epoch_model.onnx\" \\\n",
    "                                         -g 0 \\\n",
    "                                         -l \"{main_dir}/{exp}/inference_log.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17ca370",
   "metadata": {},
   "source": [
    "## Bias Visualization\n",
    "\n",
    "After inference, you can analyze the model bias by running the following code. The analysis code here will calculate the subgroup **predicted prevalence** and **AUROC** , and plot these measurements with respect to training disease prevalence differences between two subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffbe48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metric calculation\n",
    "for exp in exp_list:\n",
    "    %run ../src/utils/bias_analysis.py -d \"{main_dir}/{exp}\" \\\n",
    "                                       -r \"results__.tsv\" \\\n",
    "                                       -i \"{main_dir}/independent_test.csv\" \\\n",
    "                                       -s \"sex\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
